<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Machine Learning 101 - The Basics</title>
  <meta name="description" content="An Introduction to basic notions and techniques in Machine Learning. Get a fast overview of what is out there and when to use what in which way.">

  <!-- CSS files -->
  <link rel="stylesheet" href="http://localhost:4000/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">

  <link rel="canonical" href="http://localhost:4000/articles/2017-04/Machine-Learning-101">
  <link rel="alternate" type="application/rss+xml" title="Timo Wagner" href="http://localhost:4000/feed.xml" />

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/favicons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/favicons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/favicons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/favicons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/favicons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/favicons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/favicons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/favicons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/favicons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="http://localhost:4000/favicons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="http://localhost:4000/favicons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="http://localhost:4000/favicons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="http://localhost:4000/favicons/favicon-16x16.png">
  <link rel="manifest" href="http://localhost:4000/favicons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="http://localhost:4000/favicons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
</head>


<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <img src="https://avatars2.githubusercontent.com/u/26152358?v=3&u=3ce04d6d58ef6f11be830f4b1c59ce2db97cfec2&s=400" alt="" class="avatar">
  
  <a href="http://localhost:4000/home/" class="author_name">Timo Wagner</a>
  <span class="author_job">Yet Another Data Something Blog.</span>
  <span class="author_bio mbm">I am currently a master student at the Karlsruher Institute of Technology (KIT). I am passionated about Data Science. I like to crawl the web for data and I am also keen on machine learning algorithms.</span>
  <nav class="nav">
    <ul class="nav-list">
      <!--
      <li class="nav-item">
        <a href="http://localhost:4000/home/">home</a>
      </li>
      -->
      <li class="nav-item">
        <a href="http://localhost:4000/">blog</a>
      </li>
      <li class="nav-item">
        <a href="http://localhost:4000/categories/">categories</a>
      </li>
      <li class="nav-item">
        <a href="http://localhost:4000/archive/">archive</a>
      </li>
      <!--
      <li class="nav-item">
        <a href="http://localhost:4000/CV/">CV</a>
      </li>
      -->
    </ul>
  </nav>
  <script type="text/javascript">
  // based on http://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
      <li>
      <script>gen_mail_to_link('wagnertimo@gmx.de', 'Hello from website');</script>
      </li>
    
    
    
    
    <li><a href="http://linkedin.com/in/timo-wagner-95168213a/" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    <li><a href="http://www.xing.com/profile/Timo_Wagner44" class="social-link-item" target="_blank"><i class="fa fa-fw fa-xing"></i></a></li>
    
    
    <li><a href="http://github.com/wagnertimo" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    <li><a href="http://stackoverflow.com/users/7810379/timo-wagner?tab=profile" class="social-link-item" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i></a></li>
    
    
    
    
    
    
    
    
    
    
    
    <a href="http://stackoverflow.com/7810379/timo-wagner?tab=profile"><i class="social-link-item" target="_blank"><i class="fa fa-fw fa-stackoverflow"></i></a></li>

  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "http://localhost:4000/" >
  Home
</a>

<div class="post-image-feature">
  <img class="feature-image" src=
  
  "http://localhost:4000/img/brain.svg"
  
  alt="Machine Learning 101 - The Basics feature image">

  
</div><!-- /.image-wrap -->



<div id="post">
  <header class="post-header">
    <h1 title="Machine Learning 101 - The Basics">Machine Learning 101 - The Basics</h1>
    <span class="post-meta">
      <span class="post-date">
        2 APR 2017
      </span>
      •
      <span class="read-time" title="Estimated read time">
  
  
    9 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <p>Here you should get an overview about the most common terms and techniques in Machine Learning.</p>

<p><img src="http://donaldwhyte.co.uk/intro-to-ml/images/machinelearningalgorithms.png" alt="Machine Learning Algorithms - Overview" /></p>

<h2 id="the-statisticians-and-computer-scientists-point-of-view">The statisticians and computer scientists point-of-view</h2>

<p>The statistical perspective of machine learning frames data in the context of a hypothetical function (f) that the machine learning algorithm aims to learn. Given some input variables (Input)  the function answer the question as to what is the predicted output variable (Output).</p>

<p>Output = f(Input)</p>

<p>The inputs and outputs can be referred to as variables or vectors.</p>

<p>The computer science perspective uses a row of data to describe an entity (like a person) or an observation about an entity. As such, the columns for a row are often referred to as attributes of the observation and the rows themselves are called instances.</p>

<h2 id="the-underlying-assumption">The underlying assumption</h2>

<p>There is a common principle that underlies all supervised machine learning algorithms for predictive modeling.
Machine learning algorithms are described as learning a target function (f) that best maps input variables (X) to an output variable (Y).</p>

<p>Y = f(X)</p>

<p>This is a general learning task where we would like to make predictions in the future (Y) given new examples of input variables (X). We don’t know what the function (f) looks like or its form. If we did, we would use it directly and we would not need to learn it from data using machine learning algorithms.</p>

<p>The most common type of machine learning is to learn the mapping Y = f(X) to make predictions of Y for new X. This is called predictive modeling or predictive analytics and our goal is to make the most accurate predictions possible.</p>

<h2 id="parametric-vs-non-parametric-algorithms">Parametric vs. non-parametric algorithms</h2>

<p>what is a parametric machine learning algorithm and how is it different from a nonparametric machine learning algorithm?</p>

<p>Assumptions can greatly simplify the learning process, but can also limit what can be learned. Algorithms that simplify the function to a known form are called parametric machine learning algorithms.</p>

<p>The algorithms involve two steps:</p>

<p>Select a form for the function.
Learn the coefficients for the function from the training data.
Some examples of parametric machine learning algorithms are Linear Regression and Logistic Regression.</p>

<p>Algorithms that do not make strong assumptions about the form of the mapping function are called nonparametric machine learning algorithms. By not making assumptions, they are free to learn any functional form from the training data.</p>

<p>Non-parametric methods are often more flexible, achieve better accuracy but require a lot more data and training time.</p>

<p>Examples of nonparametric algorithms include Support Vector Machines, Neural Networks and Decision Trees.</p>

<h2 id="cross-validation">Cross-Validation</h2>

<p>our goal with applied machine learning is to develop a model to make predictions on new data.</p>

<p>That is, given new inputs like an unlabeled photo or a day of the week, we want to know if it is a picture of a dog or the estimated sales figures.</p>

<p>We want predictions.</p>

<p>On a project, we:
Try lots of data preparation schemes in order to best present the signal in the underlying problem to the learning algorithms.
We try suites of learning algorithms to best capture the relationship between the input and the outputs.
And we use resampling methods like train-test splits and k-fold cross validation to estimate the skill of models when making predictions on new data.
It is only after we have chosen our best combination of data prep, algorithm, and configurations that we can train a final model on all available data and start actually making predictions on unseen data.</p>

<p>New practitioners in the field often confuse the steps of resampling and model finalization asking questions like:</p>

<p>How do I make predictions with cross validation?
or
Which cross-validation model do I keep?</p>

<p>This is not surprising as the literature almost universally does not talk about it.</p>

<p>I hope this note has made things clearer for you. You can learn more in my post:</p>

<p><a href="http://machinelearningmastery.com/train-final-machine-learning-model/">How to Train a Final Machine Learning Model</a></p>

<h2 id="bias-and-variance-trade-off">Bias and Variance Trade-Off</h2>

<p>Machine learning algorithms can best be understood through the lens of the bias-variance trade-off.</p>

<p>Bias are the simplifying assumptions made by a model to make the target function easier to learn.</p>

<p>Generally, parametric algorithms have a high bias making them fast to learn and easier to understand but generally less flexible. In turn, they have lower predictive performance on complex problems that fail to meet the simplifying assumptions of the algorithms bias.</p>

<p>Decision trees are an example of a low bias algorithm, whereas linear regression is an example of a high-bias algorithm.</p>

<p>Variance is the amount that the estimate of the target function will change if different training data was used. The target function is estimated from the training data by a machine learning algorithm, so we should expect the algorithm to have some variance, not zero variance.</p>

<p>The k-Nearest Neighbors algorithm is an example of a high-variance algorithm, whereas Linear Discriminant Analysis is an example of a low variance algorithm.</p>

<p>The goal of any predictive modeling machine learning algorithm is to achieve low bias and low variance. In turn, the algorithm should achieve good prediction performance. The parameterization of machine learning algorithms is often a battle to balance out bias and variance.</p>

<ul>
  <li>Increasing the bias will decrease the variance.</li>
  <li>Increasing the variance will decrease the bias.</li>
</ul>

<h2 id="linear-regression">Linear regression</h2>

<p>Linear regression is perhaps one of the most well-known and well-understood algorithms in statistics and machine learning.</p>

<p>Isn’t it a technique from statistics?</p>

<p>Predictive modeling is primarily concerned with minimizing the error of a model or making the most accurate predictions possible, at the expense of explainability. We will borrow, reuse and steal algorithms from many different fields, including statistics and use them towards these ends.</p>

<p>The representation of linear regression is an equation that describes a line that best fits the relationship between the input variables (x) and the output variables (y), by finding specific weightings for the input variables called coefficients (B).</p>

<p>For example:</p>

<p>y = B0 + B1 * x</p>

<p>We will predict y given the input x and the goal of the linear regression learning algorithm is to find the values for the coefficients B0 and B1.</p>

<p>Different techniques can be used to learn the linear regression model from data, such as a linear algebra solution for ordinary least squares and gradient descent optimization.</p>

<p>Linear regression has been around for more than 200 years and has been extensively studied. Some good rules of thumb when using this technique are to remove variables that are very similar (correlated) and to remove noise from your data, if possible.</p>

<p>It is a fast and simple technique and good first algorithm to try.</p>

<h2 id="logistic-regression">Logistic regression</h2>

<p>logistic regression is another technique borrowed by machine learning from the field of statistics. It is the go-to method for binary classification problems (problems with two class values).</p>

<p>Logistic regression is like linear regression in that the goal is to find the values for the coefficients that weight each input variable.</p>

<p>Unlike linear regression, the prediction for the output is transformed using a non-linear function called the logistic function.</p>

<p>The logistic function looks like a big S and will transform any value into the range 0 to 1. This is useful because we can apply a rule to the output of the logistic function to snap values to 0 and 1 (e.g. IF less than 0.5 then output 1) and predict a class value.</p>

<p>Because of the way that the model is learned, the predictions made by logistic regression can also be used as the probability of a given data instance belonging to class 0 or class 1. This can be useful for problems where you need to give more rationale for a prediction.</p>

<p>Like linear regression, logistic regression does work better when you remove attributes that are unrelated to the output variable as well as attributes that are very similar (correlated) to each other.</p>

<p>It’s a fast model to learn and effective on binary classification problems.</p>

<h2 id="linear-discriminant-analysis">Linear Discriminant Analysis</h2>

<p>Logistic Regression is a classification algorithm traditionally limited to only two-class classification problems.</p>

<p>If you have more than two classes then the Linear Discriminant Analysis algorithm is the preferred linear classification technique.
The representation of LDA is pretty straight forward. It consists of statistical properties of your data, calculated for each class. For a single input variable this includes:</p>

<p>The mean value for each class.
The variance calculated across all classes.
Predictions are made by calculating a discriminate value for each class and making a prediction for the class with the largest value.</p>

<p>The technique assumes that the data has a Gaussian distribution (bell curve), so it is a good idea to remove outliers from your data before hand.</p>

<p>It’s a simple and powerful method for classification predictive modeling problems.</p>

<h2 id="decision-trees">Decision Trees</h2>

<p>Decision Trees are an important type of algorithm for predictive modeling machine learning.</p>

<p>The representation of the decision tree model is a binary tree. This is your binary tree from algorithms and data structures, nothing too fancy. Each node represents a single input variable (x) and a split point on that variable (assuming the variable is numeric).</p>

<p>The leaf nodes of the tree contain an output variable (y) which is used to make a prediction.  Predictions are made by walking the splits of the tree until arriving at a leaf node and output the class value at that leaf node.</p>

<p>Trees are fast to learn and very fast for making predictions. They are also often accurate for a broad range of problems and do not require any special preparation for your data.</p>

<p>Decision trees have a high variance and can yield more accurate predictions when used in an ensemble. For more infos about ensemble technique, look for appropriate ensemble section in this post further down.</p>

  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/articles/2017-04/Machine-Learning-101" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/articles/2017-04/Machine-Learning-101" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/articles/2017-04/Machine-Learning-101" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=http://localhost:4000/articles/2017-04/Machine-Learning-101" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=http://localhost:4000/articles/2017-04/Machine-Learning-101" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->


<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'https-wagnertimo-github-io';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



        <footer>
  &copy; 2017 Timo Wagner. Data Science made with <i class="fa fa-heart heart-icon"></i>
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="http://localhost:4000/js/jquery-2.1.4.min.js"></script>
<script type="text/javascript" src="http://localhost:4000/js/main.js"></script>


</body>
</html>
